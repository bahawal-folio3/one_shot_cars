{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd92536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a4c35c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, df, batch_size=32,shuffle=True,image_dir=\"\"):\n",
    "        self.batch_size = batch_size\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.indices = self.df.index.tolist()\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.indices[k] for k in index]\n",
    "        X, y = self.__get_data(batch)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.index = np.arange(len(self.indices))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.index)\n",
    "    \n",
    "    \n",
    "\n",
    "    def load_embedding(self, slice):\n",
    "        data = np.load(self.df.iloc[slice]['data'], allow_pickle=True)\n",
    "        embedding = data[0]\n",
    "        vector_size = len(embedding)//2 \n",
    "        embedding = embedding[:vector_size] - embedding[vector_size:]\n",
    "        label = data[1]\n",
    "        return embedding, label\n",
    "\n",
    "    def __get_data(self, batch):\n",
    "        X = []\n",
    "        y = []\n",
    "        for i, id in enumerate(batch):\n",
    "            img, label = self.load_embedding(batch[i])\n",
    "       \n",
    "            X.append(img)\n",
    "            y.append(label)\n",
    "        return np.array(X),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216408e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "641b63e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_validation = pd.DataFrame({'data':[f\"test_car/embeddings/{x}\" for x in os.listdir('test_car/embeddings/')]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c31c671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a9ae79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from load_model import get_reid_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33b1045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataGenerator(df_validation, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d89c14ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca929d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_loss = tf.keras.losses.CosineSimilarity(axis=1, reduction=tf.keras.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c867c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_embedding = None\n",
    "# test_label = None\n",
    "# preds = []\n",
    "# ground_truth = []\n",
    "# for i, j  in  tqdm(val_dataloader):\n",
    "#     test_embedding = i[0] \n",
    "#     test_label = j[0]\n",
    "#     embedding1 = test_embedding[:len(test_embedding)//2]\n",
    "#     embedding2 = test_embedding[len(test_embedding)//2:]\n",
    "#     label = cosine_loss(embedding1[np.newaxis], embedding2[np.newaxis]).numpy()[0] < -0.35\n",
    "#     preds.append(label)\n",
    "#     ground_truth.append(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa3fe7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(ground_truth)/len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78d16caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0477ed0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5292389068468998"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy_score(preds, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56fcb9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5292389068468998, 0.6043241086503741, 0.4259483415676265, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision_recall_fscore_support(preds, ground_truth,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "890ed8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8b53797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = cosine_loss(embedding1[np.newaxis], embedding2[np.newaxis]).numpy()[0] < -0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c82b93da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label==test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f59d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d7410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d05eec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'data':[f\"data/embeddings/{x}\" for x in os.listdir('data/embeddings/')]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e44ea75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/embeddings/validation-1.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/embeddings/validation-10.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/embeddings/validation-100.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/embeddings/validation-1000.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/embeddings/validation-10000.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   data\n",
       "0      data/embeddings/validation-1.npy\n",
       "1     data/embeddings/validation-10.npy\n",
       "2    data/embeddings/validation-100.npy\n",
       "3   data/embeddings/validation-1000.npy\n",
       "4  data/embeddings/validation-10000.npy"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1e7ecd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_car/embeddings/validation-1.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_car/embeddings/validation-10.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_car/embeddings/validation-100.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_car/embeddings/validation-1000.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_car/embeddings/validation-10000.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       data\n",
       "0      test_car/embeddings/validation-1.npy\n",
       "1     test_car/embeddings/validation-10.npy\n",
       "2    test_car/embeddings/validation-100.npy\n",
       "3   test_car/embeddings/validation-1000.npy\n",
       "4  test_car/embeddings/validation-10000.npy"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69cf16cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataGenerator(df)\n",
    "val_dataloader = DataGenerator(df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3e5b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "087b60c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D,Dropout\n",
    "from numpy import unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8d3db9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa508493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense,BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=256, kernel_size=5, activation='relu', padding='same', input_shape=(1536//2, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer='l2', bias_regularizer='l2'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',precision_m])\n",
    "# model.load_weights('D_vector.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b68e7c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 425/425 [01:51<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.507085553215215\n",
      "Recall: 0.6021314550537001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TP = 0\n",
    "# FP = 0\n",
    "# FN = 0\n",
    "\n",
    "# # Iterate over the batches in the Sequence\n",
    "# for batch_data in tqdm(val_dataloader):\n",
    "#     batch_inputs, batch_true_labels = batch_data  # Assuming the batch data contains inputs and true labels\n",
    "    \n",
    "#     # Make predictions using the model\n",
    "#     batch_pred_labels = model.predict(batch_inputs) > 0.85\n",
    "    \n",
    "#     # Convert labels to the appropriate data type\n",
    "#     batch_pred_labels = tf.cast(batch_pred_labels, tf.int32)\n",
    "#     batch_true_labels = tf.cast(batch_true_labels, tf.int32)\n",
    "    \n",
    "#     # Calculate TP, FP, FN for the batch\n",
    "#     batch_TP = tf.math.count_nonzero(tf.logical_and(tf.equal(batch_pred_labels, 1), tf.equal(batch_true_labels, 1)))\n",
    "#     batch_FP = tf.math.count_nonzero(tf.logical_and(tf.equal(batch_pred_labels, 1), tf.equal(batch_true_labels, 0)))\n",
    "#     batch_FN = tf.math.count_nonzero(tf.logical_and(tf.equal(batch_pred_labels, 0), tf.equal(batch_true_labels, 1)))\n",
    "#     batch_TN = tf.math.count_nonzero(tf.logical_and(tf.equal(batch_pred_labels, 0), tf.equal(batch_true_labels, 0)))\n",
    "\n",
    "# #     print(batch_TP,batch_FP,batch_FN,batch_TN)\n",
    "#     # Accumulate TP, FP, FN across batches\n",
    "#     TP += batch_TP\n",
    "#     FP += batch_FP\n",
    "#     FN += batch_FN\n",
    "\n",
    "# # Calculate precision and recall\n",
    "# precision = TP / (TP + FP)\n",
    "# recall = TP / (TP + FN)\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Precision:\", precision.numpy())\n",
    "# print(\"Recall:\", recall.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59dfe07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('conv1d_1D128.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2aec627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "mcp = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='d_vector.h5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_precision_m',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "import datetime\n",
    "log_dir = f\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6acad5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(train_dataloader, validation_data=val_dataloader, epochs = 100, batch_size = 32, callbacks=[mcp,tensorboard_callback,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a91846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c942cdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/425 [===========================>..] - ETA: 0s - loss: 0.7967 - accuracy: 0.7052 - precision_m: 0.6301"
     ]
    }
   ],
   "source": [
    "model.evaluate(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff688c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd5c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input-np.random.rand(1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd1227",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = np.random.rand(1536)\n",
    "model(dummy_input[np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8467f9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bahawalkhan\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using Transformer_type: vit_base_patch16_224_TransReID as a backbone\n",
      "using stride: [14, 14], and part number is num_y18 * num_x18\n",
      "using drop_path_rate is : 0.1\n",
      "using aie_xishu is : 2.5\n",
      "Loading finetune model......from model-weights/transformer_40.pth\n",
      "===========building transformer===========\n",
      "base.cls_token\n",
      "base.pos_embed\n",
      "base.patch_embed.proj.weight\n",
      "base.patch_embed.proj.bias\n",
      "base.blocks.0.norm1.weight\n",
      "base.blocks.0.norm1.bias\n",
      "base.blocks.0.attn.qkv.weight\n",
      "base.blocks.0.attn.qkv.bias\n",
      "base.blocks.0.attn.proj.weight\n",
      "base.blocks.0.attn.proj.bias\n",
      "base.blocks.0.norm2.weight\n",
      "base.blocks.0.norm2.bias\n",
      "base.blocks.0.mlp.fc1.weight\n",
      "base.blocks.0.mlp.fc1.bias\n",
      "base.blocks.0.mlp.fc2.weight\n",
      "base.blocks.0.mlp.fc2.bias\n",
      "base.blocks.1.norm1.weight\n",
      "base.blocks.1.norm1.bias\n",
      "base.blocks.1.attn.qkv.weight\n",
      "base.blocks.1.attn.qkv.bias\n",
      "base.blocks.1.attn.proj.weight\n",
      "base.blocks.1.attn.proj.bias\n",
      "base.blocks.1.norm2.weight\n",
      "base.blocks.1.norm2.bias\n",
      "base.blocks.1.mlp.fc1.weight\n",
      "base.blocks.1.mlp.fc1.bias\n",
      "base.blocks.1.mlp.fc2.weight\n",
      "base.blocks.1.mlp.fc2.bias\n",
      "base.blocks.2.norm1.weight\n",
      "base.blocks.2.norm1.bias\n",
      "base.blocks.2.attn.qkv.weight\n",
      "base.blocks.2.attn.qkv.bias\n",
      "base.blocks.2.attn.proj.weight\n",
      "base.blocks.2.attn.proj.bias\n",
      "base.blocks.2.norm2.weight\n",
      "base.blocks.2.norm2.bias\n",
      "base.blocks.2.mlp.fc1.weight\n",
      "base.blocks.2.mlp.fc1.bias\n",
      "base.blocks.2.mlp.fc2.weight\n",
      "base.blocks.2.mlp.fc2.bias\n",
      "base.blocks.3.norm1.weight\n",
      "base.blocks.3.norm1.bias\n",
      "base.blocks.3.attn.qkv.weight\n",
      "base.blocks.3.attn.qkv.bias\n",
      "base.blocks.3.attn.proj.weight\n",
      "base.blocks.3.attn.proj.bias\n",
      "base.blocks.3.norm2.weight\n",
      "base.blocks.3.norm2.bias\n",
      "base.blocks.3.mlp.fc1.weight\n",
      "base.blocks.3.mlp.fc1.bias\n",
      "base.blocks.3.mlp.fc2.weight\n",
      "base.blocks.3.mlp.fc2.bias\n",
      "base.blocks.4.norm1.weight\n",
      "base.blocks.4.norm1.bias\n",
      "base.blocks.4.attn.qkv.weight\n",
      "base.blocks.4.attn.qkv.bias\n",
      "base.blocks.4.attn.proj.weight\n",
      "base.blocks.4.attn.proj.bias\n",
      "base.blocks.4.norm2.weight\n",
      "base.blocks.4.norm2.bias\n",
      "base.blocks.4.mlp.fc1.weight\n",
      "base.blocks.4.mlp.fc1.bias\n",
      "base.blocks.4.mlp.fc2.weight\n",
      "base.blocks.4.mlp.fc2.bias\n",
      "base.blocks.5.norm1.weight\n",
      "base.blocks.5.norm1.bias\n",
      "base.blocks.5.attn.qkv.weight\n",
      "base.blocks.5.attn.qkv.bias\n",
      "base.blocks.5.attn.proj.weight\n",
      "base.blocks.5.attn.proj.bias\n",
      "base.blocks.5.norm2.weight\n",
      "base.blocks.5.norm2.bias\n",
      "base.blocks.5.mlp.fc1.weight\n",
      "base.blocks.5.mlp.fc1.bias\n",
      "base.blocks.5.mlp.fc2.weight\n",
      "base.blocks.5.mlp.fc2.bias\n",
      "base.blocks.6.norm1.weight\n",
      "base.blocks.6.norm1.bias\n",
      "base.blocks.6.attn.qkv.weight\n",
      "base.blocks.6.attn.qkv.bias\n",
      "base.blocks.6.attn.proj.weight\n",
      "base.blocks.6.attn.proj.bias\n",
      "base.blocks.6.norm2.weight\n",
      "base.blocks.6.norm2.bias\n",
      "base.blocks.6.mlp.fc1.weight\n",
      "base.blocks.6.mlp.fc1.bias\n",
      "base.blocks.6.mlp.fc2.weight\n",
      "base.blocks.6.mlp.fc2.bias\n",
      "base.blocks.7.norm1.weight\n",
      "base.blocks.7.norm1.bias\n",
      "base.blocks.7.attn.qkv.weight\n",
      "base.blocks.7.attn.qkv.bias\n",
      "base.blocks.7.attn.proj.weight\n",
      "base.blocks.7.attn.proj.bias\n",
      "base.blocks.7.norm2.weight\n",
      "base.blocks.7.norm2.bias\n",
      "base.blocks.7.mlp.fc1.weight\n",
      "base.blocks.7.mlp.fc1.bias\n",
      "base.blocks.7.mlp.fc2.weight\n",
      "base.blocks.7.mlp.fc2.bias\n",
      "base.blocks.8.norm1.weight\n",
      "base.blocks.8.norm1.bias\n",
      "base.blocks.8.attn.qkv.weight\n",
      "base.blocks.8.attn.qkv.bias\n",
      "base.blocks.8.attn.proj.weight\n",
      "base.blocks.8.attn.proj.bias\n",
      "base.blocks.8.norm2.weight\n",
      "base.blocks.8.norm2.bias\n",
      "base.blocks.8.mlp.fc1.weight\n",
      "base.blocks.8.mlp.fc1.bias\n",
      "base.blocks.8.mlp.fc2.weight\n",
      "base.blocks.8.mlp.fc2.bias\n",
      "base.blocks.9.norm1.weight\n",
      "base.blocks.9.norm1.bias\n",
      "base.blocks.9.attn.qkv.weight\n",
      "base.blocks.9.attn.qkv.bias\n",
      "base.blocks.9.attn.proj.weight\n",
      "base.blocks.9.attn.proj.bias\n",
      "base.blocks.9.norm2.weight\n",
      "base.blocks.9.norm2.bias\n",
      "base.blocks.9.mlp.fc1.weight\n",
      "base.blocks.9.mlp.fc1.bias\n",
      "base.blocks.9.mlp.fc2.weight\n",
      "base.blocks.9.mlp.fc2.bias\n",
      "base.blocks.10.norm1.weight\n",
      "base.blocks.10.norm1.bias\n",
      "base.blocks.10.attn.qkv.weight\n",
      "base.blocks.10.attn.qkv.bias\n",
      "base.blocks.10.attn.proj.weight\n",
      "base.blocks.10.attn.proj.bias\n",
      "base.blocks.10.norm2.weight\n",
      "base.blocks.10.norm2.bias\n",
      "base.blocks.10.mlp.fc1.weight\n",
      "base.blocks.10.mlp.fc1.bias\n",
      "base.blocks.10.mlp.fc2.weight\n",
      "base.blocks.10.mlp.fc2.bias\n",
      "base.blocks.11.norm1.weight\n",
      "base.blocks.11.norm1.bias\n",
      "base.blocks.11.attn.qkv.weight\n",
      "base.blocks.11.attn.qkv.bias\n",
      "base.blocks.11.attn.proj.weight\n",
      "base.blocks.11.attn.proj.bias\n",
      "base.blocks.11.norm2.weight\n",
      "base.blocks.11.norm2.bias\n",
      "base.blocks.11.mlp.fc1.weight\n",
      "base.blocks.11.mlp.fc1.bias\n",
      "base.blocks.11.mlp.fc2.weight\n",
      "base.blocks.11.mlp.fc2.bias\n",
      "base.norm.weight\n",
      "base.norm.bias\n",
      "base.fc.weight\n",
      "base.fc.bias\n",
      "bottleneck.weight\n",
      "bottleneck.bias\n",
      "bottleneck.running_mean\n",
      "bottleneck.running_var\n",
      "bottleneck.num_batches_tracked\n",
      "Loading pretrained model from model-weights/transformer_40.pth\n"
     ]
    }
   ],
   "source": [
    "from load_model import get_reid_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "005bf4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = ['car1','car2','car3','car4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d39e9061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aee2db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = {}\n",
    "for car in cars:\n",
    "    imgs[car] = [f'test_car/{car}/{x}' for x in os.listdir(f'test_car/{car}')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a406266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "test_images = []\n",
    "for car in cars:\n",
    "    test_images.extend(imgs[car])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9592f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "combinations = list(combinations(test_images, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4210cacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3065294b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('test_car/car1/1.jpeg', 'test_car/car1/2.jpeg')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a45b2407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 325/325 [00:40<00:00,  7.95it/s]\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y_hat = []\n",
    "y_pred = []\n",
    "for pair in tqdm(combinations):\n",
    "    img1 = cv2.imread(pair[0])\n",
    "    img2 = cv2.imread(pair[1])\n",
    "    img1_embedding = get_reid_embeddings(cv2.resize(img1,(256,256)))\n",
    "    img2_embedding = get_reid_embeddings(cv2.resize(img2,(256,256)))\n",
    "    embedding = np.concatenate((img1_embedding,img2_embedding), axis=0)\n",
    "    pred = model(embedding[np.newaxis])[0]\n",
    "    y_pred.append(pred)\n",
    "    y_hat.append(pair[0].split('/')[-2].split('_')[-1] == pair[1].split('/')[-2].split('_')[-1])\n",
    "#     x.append(embedding)\n",
    "#     print(pair[0].split('/')[-2].split('_')[-1] == pair[1].split('/')[-2].split('_')[-1])\n",
    "#     print(pair[0].split('/')[-2].split('_')[-1],pair[1].split('/')[-2].split('_')[-1])\n",
    "#     print(pair)\n",
    "\n",
    "#     y.append(pair[0].split('/')[-2].split('_')[-1] == pair[1].split('/')[-2].split('_')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "732c3d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.9912661], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred = [y[0] for y in y_pred]\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "845b023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "y_hat = np.array(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad0a1743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5938461538461538\n",
      "Precision: 0.3564356435643564\n",
      "Recall: 0.972972972972973\n",
      "F1-score: 0.5217391304347826\n"
     ]
    }
   ],
   "source": [
    "# def calculate_metrics(predictions, ground_truth):\n",
    "#     \"\"\"\n",
    "#     Calculates accuracy, precision, recall, and F1-score given the prediction and ground truth lists.\n",
    "#     \"\"\"\n",
    "#     true_positives = sum(1 for pred, true in zip(predictions, ground_truth) if pred == 1 and true == 1)\n",
    "#     false_positives = sum(1 for pred, true in zip(predictions, ground_truth) if pred == 1 and true == 0)\n",
    "#     false_negatives = sum(1 for pred, true in zip(predictions, ground_truth) if pred == 0 and true == 1)\n",
    "#     true_negatives = sum(1 for pred, true in zip(predictions, ground_truth) if pred == 0 and true == 0)\n",
    "\n",
    "#     accuracy = (true_positives + true_negatives) / len(predictions)\n",
    "#     precision = true_positives / (true_positives + false_positives)\n",
    "#     recall = true_positives / (true_positives + false_negatives)\n",
    "#     f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "#     return accuracy, precision, recall, f1_score\n",
    "\n",
    "\n",
    "# accuracy, precision, recall, f1_score = calculate_metrics(y_pred>0.7, y_hat)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "# print(\"Precision:\", precision)\n",
    "# print(\"Recall:\", recall)\n",
    "# print(\"F1-score:\", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fad497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad81408",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d75a454",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750700c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'data/validation_x.npy', x)\n",
    "np.save(f'data/validation_y.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6488473",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8ed162",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:,0][0].reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d8abd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
