{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b54e37ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bahawalkhan\\Anaconda3\\envs\\yolo\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\bahawalkhan\\Anaconda3\\envs\\yolo\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\bahawalkhan\\Anaconda3\\envs\\yolo\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "c:\\Users\\bahawalkhan\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using Transformer_type: vit_base_patch16_224_TransReID as a backbone\n",
      "using stride: [14, 14], and part number is num_y18 * num_x18\n",
      "using drop_path_rate is : 0.1\n",
      "using aie_xishu is : 2.5\n",
      "Loading finetune model......from model-weights/transformer_40.pth\n",
      "===========building transformer===========\n",
      "base.cls_token\n",
      "base.pos_embed\n",
      "base.patch_embed.proj.weight\n",
      "base.patch_embed.proj.bias\n",
      "base.blocks.0.norm1.weight\n",
      "base.blocks.0.norm1.bias\n",
      "base.blocks.0.attn.qkv.weight\n",
      "base.blocks.0.attn.qkv.bias\n",
      "base.blocks.0.attn.proj.weight\n",
      "base.blocks.0.attn.proj.bias\n",
      "base.blocks.0.norm2.weight\n",
      "base.blocks.0.norm2.bias\n",
      "base.blocks.0.mlp.fc1.weight\n",
      "base.blocks.0.mlp.fc1.bias\n",
      "base.blocks.0.mlp.fc2.weight\n",
      "base.blocks.0.mlp.fc2.bias\n",
      "base.blocks.1.norm1.weight\n",
      "base.blocks.1.norm1.bias\n",
      "base.blocks.1.attn.qkv.weight\n",
      "base.blocks.1.attn.qkv.bias\n",
      "base.blocks.1.attn.proj.weight\n",
      "base.blocks.1.attn.proj.bias\n",
      "base.blocks.1.norm2.weight\n",
      "base.blocks.1.norm2.bias\n",
      "base.blocks.1.mlp.fc1.weight\n",
      "base.blocks.1.mlp.fc1.bias\n",
      "base.blocks.1.mlp.fc2.weight\n",
      "base.blocks.1.mlp.fc2.bias\n",
      "base.blocks.2.norm1.weight\n",
      "base.blocks.2.norm1.bias\n",
      "base.blocks.2.attn.qkv.weight\n",
      "base.blocks.2.attn.qkv.bias\n",
      "base.blocks.2.attn.proj.weight\n",
      "base.blocks.2.attn.proj.bias\n",
      "base.blocks.2.norm2.weight\n",
      "base.blocks.2.norm2.bias\n",
      "base.blocks.2.mlp.fc1.weight\n",
      "base.blocks.2.mlp.fc1.bias\n",
      "base.blocks.2.mlp.fc2.weight\n",
      "base.blocks.2.mlp.fc2.bias\n",
      "base.blocks.3.norm1.weight\n",
      "base.blocks.3.norm1.bias\n",
      "base.blocks.3.attn.qkv.weight\n",
      "base.blocks.3.attn.qkv.bias\n",
      "base.blocks.3.attn.proj.weight\n",
      "base.blocks.3.attn.proj.bias\n",
      "base.blocks.3.norm2.weight\n",
      "base.blocks.3.norm2.bias\n",
      "base.blocks.3.mlp.fc1.weight\n",
      "base.blocks.3.mlp.fc1.bias\n",
      "base.blocks.3.mlp.fc2.weight\n",
      "base.blocks.3.mlp.fc2.bias\n",
      "base.blocks.4.norm1.weight\n",
      "base.blocks.4.norm1.bias\n",
      "base.blocks.4.attn.qkv.weight\n",
      "base.blocks.4.attn.qkv.bias\n",
      "base.blocks.4.attn.proj.weight\n",
      "base.blocks.4.attn.proj.bias\n",
      "base.blocks.4.norm2.weight\n",
      "base.blocks.4.norm2.bias\n",
      "base.blocks.4.mlp.fc1.weight\n",
      "base.blocks.4.mlp.fc1.bias\n",
      "base.blocks.4.mlp.fc2.weight\n",
      "base.blocks.4.mlp.fc2.bias\n",
      "base.blocks.5.norm1.weight\n",
      "base.blocks.5.norm1.bias\n",
      "base.blocks.5.attn.qkv.weight\n",
      "base.blocks.5.attn.qkv.bias\n",
      "base.blocks.5.attn.proj.weight\n",
      "base.blocks.5.attn.proj.bias\n",
      "base.blocks.5.norm2.weight\n",
      "base.blocks.5.norm2.bias\n",
      "base.blocks.5.mlp.fc1.weight\n",
      "base.blocks.5.mlp.fc1.bias\n",
      "base.blocks.5.mlp.fc2.weight\n",
      "base.blocks.5.mlp.fc2.bias\n",
      "base.blocks.6.norm1.weight\n",
      "base.blocks.6.norm1.bias\n",
      "base.blocks.6.attn.qkv.weight\n",
      "base.blocks.6.attn.qkv.bias\n",
      "base.blocks.6.attn.proj.weight\n",
      "base.blocks.6.attn.proj.bias\n",
      "base.blocks.6.norm2.weight\n",
      "base.blocks.6.norm2.bias\n",
      "base.blocks.6.mlp.fc1.weight\n",
      "base.blocks.6.mlp.fc1.bias\n",
      "base.blocks.6.mlp.fc2.weight\n",
      "base.blocks.6.mlp.fc2.bias\n",
      "base.blocks.7.norm1.weight\n",
      "base.blocks.7.norm1.bias\n",
      "base.blocks.7.attn.qkv.weight\n",
      "base.blocks.7.attn.qkv.bias\n",
      "base.blocks.7.attn.proj.weight\n",
      "base.blocks.7.attn.proj.bias\n",
      "base.blocks.7.norm2.weight\n",
      "base.blocks.7.norm2.bias\n",
      "base.blocks.7.mlp.fc1.weight\n",
      "base.blocks.7.mlp.fc1.bias\n",
      "base.blocks.7.mlp.fc2.weight\n",
      "base.blocks.7.mlp.fc2.bias\n",
      "base.blocks.8.norm1.weight\n",
      "base.blocks.8.norm1.bias\n",
      "base.blocks.8.attn.qkv.weight\n",
      "base.blocks.8.attn.qkv.bias\n",
      "base.blocks.8.attn.proj.weight\n",
      "base.blocks.8.attn.proj.bias\n",
      "base.blocks.8.norm2.weight\n",
      "base.blocks.8.norm2.bias\n",
      "base.blocks.8.mlp.fc1.weight\n",
      "base.blocks.8.mlp.fc1.bias\n",
      "base.blocks.8.mlp.fc2.weight\n",
      "base.blocks.8.mlp.fc2.bias\n",
      "base.blocks.9.norm1.weight\n",
      "base.blocks.9.norm1.bias\n",
      "base.blocks.9.attn.qkv.weight\n",
      "base.blocks.9.attn.qkv.bias\n",
      "base.blocks.9.attn.proj.weight\n",
      "base.blocks.9.attn.proj.bias\n",
      "base.blocks.9.norm2.weight\n",
      "base.blocks.9.norm2.bias\n",
      "base.blocks.9.mlp.fc1.weight\n",
      "base.blocks.9.mlp.fc1.bias\n",
      "base.blocks.9.mlp.fc2.weight\n",
      "base.blocks.9.mlp.fc2.bias\n",
      "base.blocks.10.norm1.weight\n",
      "base.blocks.10.norm1.bias\n",
      "base.blocks.10.attn.qkv.weight\n",
      "base.blocks.10.attn.qkv.bias\n",
      "base.blocks.10.attn.proj.weight\n",
      "base.blocks.10.attn.proj.bias\n",
      "base.blocks.10.norm2.weight\n",
      "base.blocks.10.norm2.bias\n",
      "base.blocks.10.mlp.fc1.weight\n",
      "base.blocks.10.mlp.fc1.bias\n",
      "base.blocks.10.mlp.fc2.weight\n",
      "base.blocks.10.mlp.fc2.bias\n",
      "base.blocks.11.norm1.weight\n",
      "base.blocks.11.norm1.bias\n",
      "base.blocks.11.attn.qkv.weight\n",
      "base.blocks.11.attn.qkv.bias\n",
      "base.blocks.11.attn.proj.weight\n",
      "base.blocks.11.attn.proj.bias\n",
      "base.blocks.11.norm2.weight\n",
      "base.blocks.11.norm2.bias\n",
      "base.blocks.11.mlp.fc1.weight\n",
      "base.blocks.11.mlp.fc1.bias\n",
      "base.blocks.11.mlp.fc2.weight\n",
      "base.blocks.11.mlp.fc2.bias\n",
      "base.norm.weight\n",
      "base.norm.bias\n",
      "base.fc.weight\n",
      "base.fc.bias\n",
      "bottleneck.weight\n",
      "bottleneck.bias\n",
      "bottleneck.running_mean\n",
      "bottleneck.running_var\n",
      "bottleneck.num_batches_tracked\n",
      "Loading pretrained model from model-weights/transformer_40.pth\n"
     ]
    }
   ],
   "source": [
    "from load_model import get_reid_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a507b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7768de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../augmented_cars_data'\n",
    "mode = 'test-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e81d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cars(car_dir):\n",
    "    return [f'{base_dir}/{x}' for x in os.listdir(car_dir) if (os.path.isdir(f\"{car_dir}/{x}\" )) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a963ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37a75a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../augmented_cars_data/car1 augmented/IMG_4029.MOV_1.jpg', '../augmented_cars_data/car1 augmented/IMG_4029.MOV_10.jpg', '../augmented_cars_data/car1 augmented/IMG_4029.MOV_100.jpg', '../augmented_cars_data/car1 augmented/IMG_4029.MOV_101.jpg', '../augmented_cars_data/car1 augmented/IMG_4029.MOV_102.jpg']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def get_image_list(car_dir):\n",
    "    imgs = []\n",
    "    for source_dir in get_cars(car_dir):\n",
    "        source_dir_path = f'{car_dir}/{source_dir}'\n",
    "        my_list = os.listdir(source_dir_path)\n",
    "        imgs.extend([source_dir +'/'+ x for x in my_list])\n",
    "    return imgs\n",
    "img_lst = [x for x in get_image_list(base_dir)]\n",
    "\n",
    "len(img_lst)\n",
    "imgs = img_lst \n",
    "print(imgs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a6889d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 25.97it/s]\n",
      "100%|██████████| 194112/194112 [06:12<00:00, 520.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intra-directory pairs: 194112\n",
      "\n",
      "Inter-directory pairs: 194112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from itertools import combinations, product\n",
    "from tqdm import tqdm\n",
    "def generate_pairs(dir_list, num_intra_pairs_per_dir, num_inter_pairs):\n",
    "    intra_pairs = []\n",
    "    inter_pairs = []\n",
    "\n",
    "    # Iterate through each directory\n",
    "    for directory in tqdm(dir_list):\n",
    "        # Get a list of all image files in the directory\n",
    "        image_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        # Generate intra-directory pairs\n",
    "        # image_files = random.sample(image_files,10)\n",
    "        combs = combinations(image_files, 2)\n",
    "        for com in combs:\n",
    "            intra_pairs.append([com[0],com[1],1])\n",
    "\n",
    "    # Generate inter-directory pairs\n",
    "    for _ in tqdm(range(len(intra_pairs))):\n",
    "        # Randomly select two different directories\n",
    "        dir1, dir2 = random.sample(dir_list, 2)\n",
    "\n",
    "        # Randomly select an image from each directory\n",
    "        image1 = random.choice([os.path.join(dir1, file) for file in os.listdir(dir1) if file.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "        image2 = random.choice([os.path.join(dir2, file) for file in os.listdir(dir2) if file.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "\n",
    "        inter_pairs.append((image1, image2,0))\n",
    "\n",
    "    return intra_pairs, inter_pairs\n",
    "\n",
    "# Example usage:\n",
    "directories = get_cars(base_dir)\n",
    "num_intra_pairs_per_dir = 5\n",
    "num_inter_pairs = 10\n",
    "\n",
    "intra_pairs, inter_pairs = generate_pairs(directories, num_intra_pairs_per_dir, num_inter_pairs)\n",
    "print(\"Intra-directory pairs:\", len(intra_pairs))\n",
    "print(\"Inter-directory pairs:\",len(inter_pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96f36638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194112\n",
      "194112\n"
     ]
    }
   ],
   "source": [
    "# combinations = list(itertools.combinations(imgs, 2))\n",
    "print(len(intra_pairs))\n",
    "print(len(inter_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9641e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('../augmented_cars_data/car1 augmented\\\\IMG_4029.MOV_275.jpg',\n",
       "  '../augmented_cars_data/car1 orignal\\\\IMG_4029.MOV_59.jpg',\n",
       "  0),\n",
       " ('../augmented_cars_data/car1 augmented\\\\IMG_4029.MOV_351.jpg',\n",
       "  '../augmented_cars_data/car2 augmented\\\\2332.jpg',\n",
       "  0),\n",
       " ('../augmented_cars_data/car1 orignal\\\\IMG_4029.MOV_40.jpg',\n",
       "  '../augmented_cars_data/car1 augmented\\\\IMG_4029.MOV_233.jpg',\n",
       "  0),\n",
       " ('../augmented_cars_data/car1 orignal\\\\IMG_4029.MOV_142.jpg',\n",
       "  '../augmented_cars_data/car1 augmented\\\\IMG_4029.MOV_381.jpg',\n",
       "  0),\n",
       " ('../augmented_cars_data/car2 augmented\\\\2347.jpg',\n",
       "  '../augmented_cars_data/car2 orignal\\\\2329.jpg',\n",
       "  0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f4e7b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same_pair = [pair for pair in combinations if pair[0].split('-')[0] == pair[1].split('-')[0]]\n",
    "# diff_pair = [pair for pair in combinations if pair[0].split('-')[0] != pair[1].split('-')[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e17b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f'{mode}-same_pairs.txt', 'w') as fp:\n",
    "    for pair in intra_pairs:\n",
    "        fp.write(f'{pair[0]},{pair[1]},{pair[2]}\\n')\n",
    "with open(f'{mode}-diff_pairs.txt', 'w') as fp:\n",
    "    for pair in inter_pairs:\n",
    "        fp.write(f'{pair[0]},{pair[1]},{pair[2]}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3ce724f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../augmented_cars_data/car1 augmented\\\\IMG_4029.MOV_1.jpg,../augmented_cars_data/car1 augmented\\\\IMG_4029.MOV_10.jpg,1\\n', '../augmented_cars_data/car1 augmented\\\\IMG_4029.MOV_1.jpg,../augmented_cars_data/car1 augmented\\\\IMG_4029.MOV_100.jpg,1\\n', '../augmented_cars_data/car1 augmented\\\\IMG_4029.MOV_1.jpg,../augmented_cars_data/car1 augmented\\\\IMG_4029.MOV_101.jpg,1\\n', '../augmented_cars_data/car1 augmented\\\\IMG_4029.MOV_1.jpg,../augmented_cars_data/car1 augmented\\\\IMG_4029.MOV_102.jpg,1\\n', '../augmented_cars_data/car1 augmented\\\\IMG_4029.MOV_1.jpg,../augmented_cars_data/car1 augmented\\\\IMG_4029.MOV_103.jpg,1\\n']\n"
     ]
    }
   ],
   "source": [
    "same_pair = open(f'{mode}-same_pairs.txt','r').readlines()\n",
    "diff_pair = open(f'{mode}-diff_pairs.txt','r').readlines()\n",
    "print(same_pair[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0abc6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../augmented_cars_data\\\\car1 augmented\\\\IMG_4029.MOV_1.jpg', '../augmented_cars_data\\\\car1 augmented\\\\IMG_4029.MOV_10.jpg', '../augmented_cars_data\\\\car1 augmented\\\\IMG_4029.MOV_100.jpg', '../augmented_cars_data\\\\car1 augmented\\\\IMG_4029.MOV_101.jpg', '../augmented_cars_data\\\\car1 augmented\\\\IMG_4029.MOV_102.jpg']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "def get_image_paths(root_dir, extensions=[\".jpg\", \".jpeg\", \".png\"]):\n",
    "    image_paths = []\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for file in filenames:\n",
    "            if any(file.lower().endswith(ext) for ext in extensions):\n",
    "                image_paths.append(os.path.join(dirpath, file))\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "# Example usage:\n",
    "root_directory = '../augmented_cars_data'\n",
    "image_paths = get_image_paths(root_directory)\n",
    "\n",
    "# Print the list of image file paths\n",
    "print(image_paths[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17a3176e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../augmented_cars_data_embeddings'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_dir = '../augmented_cars_data' + '_embeddings'\n",
    "dest_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "980c1e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [01:28<00:00, 12.96it/s]\n"
     ]
    }
   ],
   "source": [
    "for img_path in tqdm(image_paths):\n",
    "    img = cv2.imread(img_path)\n",
    "    img_embedding =  get_reid_embeddings(cv2.resize(img,(256,256))/255)\n",
    "    save_path = img_path.replace(base_dir,dest_dir).replace('jpg','npy')\n",
    "    save_dir = os.path.dirname(save_path)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    np.save(save_path, img_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8509138c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74480e71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_combined_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\car_matching_model\\common\\dataloader.ipynb Cell 17\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/car_matching_model/common/dataloader.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m unique_images \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/car_matching_model/common/dataloader.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m a,b \u001b[39min\u001b[39;00m new_combined_list:\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/car_matching_model/common/dataloader.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     unique_images\u001b[39m.\u001b[39madd(a)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/car_matching_model/common/dataloader.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     unique_images\u001b[39m.\u001b[39madd(b)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_combined_list' is not defined"
     ]
    }
   ],
   "source": [
    "unique_images = set()\n",
    "for a,b in new_combined_list:\n",
    "    unique_images.add(a)\n",
    "    unique_images.add(b)\n",
    "len(unique_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8036311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_images = list(unique_images)\n",
    "unique_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efba73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def augment_image_for_lighting(image):\n",
    "    # Randomly adjust brightness and contrast\n",
    "    alpha = random.uniform(0.7, 1.3)  # Adjust brightness\n",
    "    beta = random.uniform(0.7, 1.3)   # Adjust contrast\n",
    "    augmented_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "\n",
    "    # Randomly apply Gaussian blur\n",
    "    if random.random() < 0.5:\n",
    "        blur_kernel_size = random.randint(1, 5) * 2 + 1\n",
    "        augmented_image = cv2.GaussianBlur(augmented_image, (blur_kernel_size, blur_kernel_size), 0)\n",
    "\n",
    "    # Randomly add noise\n",
    "    if random.random() < 0.5:\n",
    "        noise = np.random.normal(0, 25, image.shape).astype(np.uint8)\n",
    "        augmented_image = cv2.add(augmented_image, noise)\n",
    "\n",
    "    return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8009d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_map = {}\n",
    "for img in tqdm(unique_images):\n",
    "    img_dir,img_name = img.split('-')[0], '-'.join(img.split('-')[1:]) \n",
    "\n",
    "    try:\n",
    "        \n",
    "        image = cv2.imread(f\"{base_dir}/{img_dir}/{img_name}\")\n",
    "    #     print(image)\n",
    "        image = augment_image_for_lighting(image)\n",
    "        embedding_map[img] = get_reid_embeddings(cv2.resize(image,(256,256))/255)\n",
    "    except:\n",
    "        print(f'count not read {base_dir}/{img_dir}/{img_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fde617",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "count = 1\n",
    "if not os.path.exists(f'{base_dir}_embeddings'):\n",
    "    os.mkdir(f'{base_dir}_embeddings')\n",
    "\n",
    "for pair in tqdm(new_combined_list[2021656:]):\n",
    "    img1 = pair[0] \n",
    "    img2 = pair[1]\n",
    "    try:\n",
    "        if img1.endswith('.jpg')  and img2.endswith('jpg'):\n",
    "            img1_label = pair[0].split('-')[0]\n",
    "            img2_label = pair[1].split('-')[0]\n",
    "            img1_embedding = embedding_map[img1]\n",
    "            img2_embedding = embedding_map[img2]\n",
    "            embedding = np.concatenate((img1_embedding, img2_embedding), axis=0)\n",
    "    #         print(embedding.shape)\n",
    "            label = img2_label==img1_label\n",
    "            # print(label)\n",
    "            # print(img2_label, img1_label)\n",
    "            np.save(f'{base_dir}_embeddings/{count}.npy',np.array([embedding,label]))\n",
    "            count+=1\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b2ceae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c022daa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
